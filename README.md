# ğŸ¦  COVID-19 ETL with PySpark & Streamlit  

Este proyecto implementa un **pipeline ETL (Extract, Transform, Load)** para analizar los datos de COVID-19 en **Argentina, Chile, Bolivia, Paraguay, Brasil y Uruguay**.  

Usamos **PySpark** para procesar grandes volÃºmenes de datos y **Streamlit** para crear un **dashboard interactivo**.  

## ğŸ“Œ TecnologÃ­as Utilizadas  

âœ… **Python** para el desarrollo general.  
âœ… **PySpark** para la transformaciÃ³n y procesamiento de datos.  
âœ… **Pandas** para manipulaciÃ³n inicial de datos.  
âœ… **Streamlit** para visualizar datos en un dashboard.  
âœ… **Pytest** para pruebas unitarias.  
âœ… **PEP8, pylint, mypy** para mantener cÃ³digo limpio y bien documentado.  

---

## ğŸ“‚ Estructura del Proyecto  

```
covid_pyspark_project/
â”‚â”€â”€ .data/                    # Carpeta oculta donde se guardan los datos procesados
â”‚â”€â”€ notebooks/                 # AnÃ¡lisis exploratorio de datos (EDA)
â”‚   â”œâ”€â”€ eda.ipynb              # Notebook con descarga y anÃ¡lisis inicial de los datos
â”‚â”€â”€ src/                       # CÃ³digo fuente del proyecto
â”‚   â”œâ”€â”€ main.py                # Ejecuta todo el pipeline ETL
â”‚   â”œâ”€â”€ etl.py                 # Clase ETL para procesamiento en PySpark
â”‚   â”œâ”€â”€ data_loader.py         # Descarga y guarda los datos COVID-19
â”‚   â”œâ”€â”€ dashboard.py           # Dashboard interactivo con Streamlit
â”‚   â”œâ”€â”€ utils.py               # Funciones auxiliares (si es necesario)
â”‚â”€â”€ tests/                     # Pruebas unitarias con pytest
â”‚   â”œâ”€â”€ test_data_loader.py    # Test para DataLoader
â”‚   â”œâ”€â”€ test_etl.py            # Test para ETL
â”‚   â”œâ”€â”€ test_dashboard.py      # Test para Dashboard
â”‚â”€â”€ .gitignore                 # Archivos a ignorar en Git
â”‚â”€â”€ requirements.txt           # Dependencias del proyecto
â”‚â”€â”€ README.md                  # ExplicaciÃ³n del proyecto
â”‚â”€â”€ pyproject.toml             # ConfiguraciÃ³n de formato y linting
â”‚â”€â”€ setup.cfg                  # Reglas de PEP8, mypy, pylint
â”‚â”€â”€ tox.ini                    # ConfiguraciÃ³n para pruebas automatizadas
â”‚â”€â”€ Makefile                   # Comandos para facilitar ejecuciÃ³n de tareas
```

---

## âš™ï¸ ExplicaciÃ³n de los MÃ³dulos  

### ğŸ“Œ `data_loader.py`  

ğŸ”¹ Descarga el dataset desde Our World In Data.  
ğŸ”¹ Filtra los datos solo para los paÃ­ses seleccionados.  
ğŸ”¹ Guarda el dataset en **`.data/covid_data.csv`** para que pueda ser procesado en el ETL.  

### ğŸ“Œ `etl.py`  

ğŸ”¹ Carga los datos filtrados usando **PySpark**.  
ğŸ”¹ Realiza **mÃ­nima transformaciÃ³n**: selecciona columnas clave y elimina valores nulos.  
ğŸ”¹ Guarda los datos transformados en formato **Parquet** (`.data/covid_data.parquet`).  

### ğŸ“Œ `dashboard.py`  

ğŸ”¹ Carga los datos transformados en PySpark.  
ğŸ”¹ Muestra los datos en una interfaz web interactiva con **Streamlit**.  

### ğŸ“Œ `main.py`  

ğŸ”¹ Ejecuta **todo el pipeline**:  
   1. Descarga y filtra los datos (`data_loader.py`).  
   2. Ejecuta la transformaciÃ³n en PySpark (`etl.py`).  
   3. Guarda el resultado en formato Parquet.  
   4. Muestra un mensaje de Ã©xito en la consola.  

### ğŸ“Œ `notebooks/eda.ipynb`  

ğŸ”¹ Realiza **anÃ¡lisis exploratorio** del dataset de COVID-19.  
ğŸ”¹ Muestra grÃ¡ficos con la evoluciÃ³n de casos por paÃ­s.  
ğŸ”¹ Aplica **promedio mÃ³vil** para suavizar tendencias.  

### ğŸ“Œ Carpeta `.data/`  

ğŸ”¹ Es una **carpeta oculta** donde se guardan los datos (`covid_data.csv` y `covid_data.parquet`).  

### ğŸ“Œ `tests/`  

ğŸ”¹ Contiene pruebas unitarias para verificar que las funciones del ETL y el dashboard funcionan correctamente.  

---

## ğŸƒ CÃ³mo Ejecutar el Proyecto  

### ğŸ“Œ 1ï¸âƒ£ Instalar dependencias  

Ejecuta el siguiente comando para instalar todos los paquetes necesarios:  

```sh
pip install -r requirements.txt
```

### ğŸ“Œ 2ï¸âƒ£ Ejecutar el ETL  

Para procesar los datos en PySpark y guardarlos en formato Parquet, ejecuta:  

```sh
python src/main.py
```

### ğŸ“Œ 3ï¸âƒ£ Ejecutar el Dashboard  

Si quieres visualizar los datos en un dashboard interactivo, usa:  

```sh
streamlit run src/dashboard.py
```

---

## âœ… Pruebas Unitarias  

Para ejecutar las pruebas unitarias y verificar que todo funciona correctamente:  

```sh
pytest tests/
```

---

## ğŸ¯ Mejoras Futuras  

ğŸ”¹ Agregar mÃ¡s anÃ¡lisis exploratorio al notebook.  
ğŸ”¹ Incluir modelos de predicciÃ³n de COVID-19.  
ğŸ”¹ Conectar con una base de datos SQL en lugar de archivos locales.  

---
